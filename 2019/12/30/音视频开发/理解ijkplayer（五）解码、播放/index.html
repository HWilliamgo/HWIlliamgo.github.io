<!DOCTYPE html>
<html lang="zh-CN">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="https://s1.ax1x.com/2020/03/28/GkotgK.th.jpg">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="HWilliamgo">
  <meta name="keywords" content="">
  <title>理解ijkplayer（五）解码、播放 - William的小星球</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/5.12.1/css/all.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/mdbootstrap/4.13.0/css/mdb.min.css" />
<link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css" />

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link  rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css" />

<link  rel="stylesheet" href="/css/main.css" />


  <link defer rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />


<!-- 自定义样式保持在最底部 -->


<meta name="generator" content="Hexo 4.2.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>William的小星球</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">首页</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">归档</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">分类</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">标签</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">关于</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background" parallax=true
         style="background: url('https://w.wallhaven.cc/full/39/wallhaven-39joqy.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              
                <p class="mt-3 post-meta">
                  <i class="fas fa-calendar-alt" aria-hidden="true"></i>
                  星期一, 十二月 30日 2019, 11:18 晚上
                </p>
              

              <p class="mt-1">
                
                  
                  <span class="post-meta">
                    <i class="far fa-chart-bar"></i>
                    8.5k 字
                  </span>
                

                
                  
                  <span class="post-meta">
                      <i class="far fa-clock"></i>
                      47 分钟
                  </span>
                

                
                  <!-- 不蒜子统计文章PV -->
                  
                  <span id="busuanzi_container_page_pv" class="post-meta" style="display: none">
                    <i class="far fa-eye" aria-hidden="true"></i>
                    <span id="busuanzi_value_page_pv"></span> 次
                  </span>
                
              </p>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5 z-depth-3" id="board">
          <div class="post-content mx-auto" id="post">
            
              <p
                class="note note-warning">本文最后更新于：星期四, 五月 14日 2020, 3:38 下午</p>
            
            <div class="markdown-body">
              <blockquote>
<p>前言</p>
<p>我是一名打算走音视频路线的android开发者。以此系列文章开始，记录我的音视频开发学习之路</p>
<p>ijkplayer系列文章目录：<br><a href="https://www.jianshu.com/writer#/notebooks/40971763/notes/56760993/preview" target="_blank" rel="noopener">理解ijkplayer（一）：开始</a></p>
<p><a href="https://www.jianshu.com/p/b5a2584e03f1" target="_blank" rel="noopener">理解ijkplayer（二）项目结构分析</a></p>
<p><a href="https://www.jianshu.com/p/0501be9cf4bf" target="_blank" rel="noopener">理解ijkplayer（三）从Java层开始初始化</a></p>
<p><a href="https://www.jianshu.com/p/f633da0db4dd" target="_blank" rel="noopener">理解ijkplayer（四）拉流</a></p>
<p><a href="https://www.jianshu.com/p/1e10507f18b6" target="_blank" rel="noopener">理解ijkplayer（五）解码、播放</a></p>
</blockquote>
<hr>
<h2 id="1-解码线程"><a href="#1-解码线程" class="headerlink" title="1 解码线程"></a>1 解码线程</h2><h3 id="简略版代码："><a href="#简略版代码：" class="headerlink" title="简略版代码："></a>简略版代码：</h3><p>解码线程位于：<code>strem_component_open()</code>中，简略版如下：</p>
<pre><code class="c">static int stream_component_open(FFPlayer *ffp, int stream_index)
{
      AVCodecContext *avctx;//解码器上下文
        AVCodec *codec = NULL;//解码器
    //找到解码器
    codec = avcodec_find_decoder(avctx-&gt;codec_id);

      switch (avctx-&gt;codec_type) {
    case AVMEDIA_TYPE_AUDIO:
        ret = audio_open(ffp, channel_layout, nb_channels, sample_rate, &amp;is-&gt;audio_tgt);
           //decoder初始化
        decoder_init(&amp;is-&gt;auddec, avctx, &amp;is-&gt;audioq, is-&gt;continue_read_thread);
                //decoder启动，启动audio_thread线程
        if ((ret = decoder_start(&amp;is-&gt;auddec, audio_thread, ffp, &quot;ff_audio_dec&quot;)) &lt; 0)
            goto out;
        break;
    case AVMEDIA_TYPE_VIDEO:
        //decoder初始化
        decoder_init(&amp;is-&gt;viddec, avctx, &amp;is-&gt;videoq, is-&gt;continue_read_thread);
        ffp-&gt;node_vdec = ffpipeline_open_video_decoder(ffp-&gt;pipeline, ffp);
        if (!ffp-&gt;node_vdec)
          goto fail;
        //解码器开始
        if ((ret = decoder_start(&amp;is-&gt;viddec, video_thread, ffp, &quot;ff_video_dec&quot;)) &lt; 0)
          goto out;
        break;
      case AVMEDIA_TYPE_SUBTITLE:
        //decoder初始化
        decoder_init(&amp;is-&gt;subdec, avctx, &amp;is-&gt;subtitleq, is-&gt;continue_read_thread);
        //解码器开始
        if ((ret = decoder_start(&amp;is-&gt;subdec, subtitle_thread, ffp, &quot;ff_subtitle_dec&quot;)) &lt; 0)
            goto out;
        break;
}</code></pre>
<h3 id="完整版代码："><a href="#完整版代码：" class="headerlink" title="完整版代码："></a>完整版代码：</h3><pre><code class="c">/* open a given stream. Return 0 if OK */
static int stream_component_open(FFPlayer *ffp, int stream_index)
{
    VideoState *is = ffp-&gt;is;
    AVFormatContext *ic = is-&gt;ic;
    AVCodecContext *avctx;//解码器上下文
    AVCodec *codec = NULL;//解码器
    const char *forced_codec_name = NULL;
    AVDictionary *opts = NULL;
    AVDictionaryEntry *t = NULL;
    int sample_rate, nb_channels;
    int64_t channel_layout;
    int ret = 0;
    int stream_lowres = ffp-&gt;lowres;

    if (stream_index &lt; 0 || stream_index &gt;= ic-&gt;nb_streams)
        return -1;
    avctx = avcodec_alloc_context3(NULL);
    if (!avctx)
        return AVERROR(ENOMEM);
    //将AVCodecParameters中的变量赋值给AVCodecContext
    ret = avcodec_parameters_to_context(avctx, ic-&gt;streams[stream_index]-&gt;codecpar);
    if (ret &lt; 0)
        goto fail;
    av_codec_set_pkt_timebase(avctx, ic-&gt;streams[stream_index]-&gt;time_base);
    //找到解码器
    codec = avcodec_find_decoder(avctx-&gt;codec_id);

    switch (avctx-&gt;codec_type) {
        case AVMEDIA_TYPE_AUDIO   : is-&gt;last_audio_stream    = stream_index; forced_codec_name = ffp-&gt;audio_codec_name; break;
        case AVMEDIA_TYPE_SUBTITLE: is-&gt;last_subtitle_stream = stream_index; forced_codec_name = ffp-&gt;subtitle_codec_name; break;
        case AVMEDIA_TYPE_VIDEO   : is-&gt;last_video_stream    = stream_index; forced_codec_name = ffp-&gt;video_codec_name; break;
        default: break;
    }
    if (forced_codec_name)
        codec = avcodec_find_decoder_by_name(forced_codec_name);
    if (!codec) {
        if (forced_codec_name) av_log(NULL, AV_LOG_WARNING,
                                      &quot;No codec could be found with name &#39;%s&#39;\n&quot;, forced_codec_name);
        else                   av_log(NULL, AV_LOG_WARNING,
                                      &quot;No codec could be found with id %d\n&quot;, avctx-&gt;codec_id);
        ret = AVERROR(EINVAL);
        goto fail;
    }

    avctx-&gt;codec_id = codec-&gt;id;
    if(stream_lowres &gt; av_codec_get_max_lowres(codec)){
        av_log(avctx, AV_LOG_WARNING, &quot;The maximum value for lowres supported by the decoder is %d\n&quot;,
                av_codec_get_max_lowres(codec));
        stream_lowres = av_codec_get_max_lowres(codec);
    }
    av_codec_set_lowres(avctx, stream_lowres);

#if FF_API_EMU_EDGE
    if(stream_lowres) avctx-&gt;flags |= CODEC_FLAG_EMU_EDGE;
#endif
    if (ffp-&gt;fast)
        avctx-&gt;flags2 |= AV_CODEC_FLAG2_FAST;
#if FF_API_EMU_EDGE
    if(codec-&gt;capabilities &amp; AV_CODEC_CAP_DR1)
        avctx-&gt;flags |= CODEC_FLAG_EMU_EDGE;
#endif

    opts = filter_codec_opts(ffp-&gt;codec_opts, avctx-&gt;codec_id, ic, ic-&gt;streams[stream_index], codec);
    if (!av_dict_get(opts, &quot;threads&quot;, NULL, 0))
        av_dict_set(&amp;opts, &quot;threads&quot;, &quot;auto&quot;, 0);
    if (stream_lowres)
        av_dict_set_int(&amp;opts, &quot;lowres&quot;, stream_lowres, 0);
    if (avctx-&gt;codec_type == AVMEDIA_TYPE_VIDEO || avctx-&gt;codec_type == AVMEDIA_TYPE_AUDIO)
        av_dict_set(&amp;opts, &quot;refcounted_frames&quot;, &quot;1&quot;, 0);
    if ((ret = avcodec_open2(avctx, codec, &amp;opts)) &lt; 0) {
        goto fail;
    }
    if ((t = av_dict_get(opts, &quot;&quot;, NULL, AV_DICT_IGNORE_SUFFIX))) {
        av_log(NULL, AV_LOG_ERROR, &quot;Option %s not found.\n&quot;, t-&gt;key);
#ifdef FFP_MERGE
        ret =  AVERROR_OPTION_NOT_FOUND;
        goto fail;
#endif
    }

    is-&gt;eof = 0;
    ic-&gt;streams[stream_index]-&gt;discard = AVDISCARD_DEFAULT;
    switch (avctx-&gt;codec_type) {
    case AVMEDIA_TYPE_AUDIO:
#if CONFIG_AVFILTER
        {
            AVFilterContext *sink;

            is-&gt;audio_filter_src.freq           = avctx-&gt;sample_rate;
            is-&gt;audio_filter_src.channels       = avctx-&gt;channels;
            is-&gt;audio_filter_src.channel_layout = get_valid_channel_layout(avctx-&gt;channel_layout, avctx-&gt;channels);
            is-&gt;audio_filter_src.fmt            = avctx-&gt;sample_fmt;
            SDL_LockMutex(ffp-&gt;af_mutex);
            if ((ret = configure_audio_filters(ffp, ffp-&gt;afilters, 0)) &lt; 0) {
                SDL_UnlockMutex(ffp-&gt;af_mutex);
                goto fail;
            }
            ffp-&gt;af_changed = 0;
            SDL_UnlockMutex(ffp-&gt;af_mutex);
            sink = is-&gt;out_audio_filter;
            sample_rate    = av_buffersink_get_sample_rate(sink);
            nb_channels    = av_buffersink_get_channels(sink);
            channel_layout = av_buffersink_get_channel_layout(sink);
        }
#else
        sample_rate    = avctx-&gt;sample_rate;
        nb_channels    = avctx-&gt;channels;
        channel_layout = avctx-&gt;channel_layout;
#endif

        /* prepare audio output */
        //audio_open方法是在做什么？
        if ((ret = audio_open(ffp, channel_layout, nb_channels, sample_rate, &amp;is-&gt;audio_tgt)) &lt; 0)
            goto fail;
        ffp_set_audio_codec_info(ffp, AVCODEC_MODULE_NAME, avcodec_get_name(avctx-&gt;codec_id));
        is-&gt;audio_hw_buf_size = ret;
        is-&gt;audio_src = is-&gt;audio_tgt;
        is-&gt;audio_buf_size  = 0;
        is-&gt;audio_buf_index = 0;

        /* init averaging filter */
        is-&gt;audio_diff_avg_coef  = exp(log(0.01) / AUDIO_DIFF_AVG_NB);
        is-&gt;audio_diff_avg_count = 0;
        /* since we do not have a precise anough audio FIFO fullness,
           we correct audio sync only if larger than this threshold */
        is-&gt;audio_diff_threshold = 2.0 * is-&gt;audio_hw_buf_size / is-&gt;audio_tgt.bytes_per_sec;

        is-&gt;audio_stream = stream_index;
        is-&gt;audio_st = ic-&gt;streams[stream_index];
        //decoder初始化
        decoder_init(&amp;is-&gt;auddec, avctx, &amp;is-&gt;audioq, is-&gt;continue_read_thread);
        if ((is-&gt;ic-&gt;iformat-&gt;flags &amp; (AVFMT_NOBINSEARCH | AVFMT_NOGENSEARCH | AVFMT_NO_BYTE_SEEK)) &amp;&amp; !is-&gt;ic-&gt;iformat-&gt;read_seek) {
            is-&gt;auddec.start_pts = is-&gt;audio_st-&gt;start_time;
            is-&gt;auddec.start_pts_tb = is-&gt;audio_st-&gt;time_base;
        }
        //decoder启动，启动audio_thread线程
        if ((ret = decoder_start(&amp;is-&gt;auddec, audio_thread, ffp, &quot;ff_audio_dec&quot;)) &lt; 0)
            goto out;
        SDL_AoutPauseAudio(ffp-&gt;aout, 0);
        break;
    case AVMEDIA_TYPE_VIDEO:
        is-&gt;video_stream = stream_index;
        is-&gt;video_st = ic-&gt;streams[stream_index];
        //async_init_decoder是一个option，默认是0
        if (ffp-&gt;async_init_decoder) {
            while (!is-&gt;initialized_decoder) {
                SDL_Delay(5);
            }
            if (ffp-&gt;node_vdec) {
                is-&gt;viddec.avctx = avctx;
                ret = ffpipeline_config_video_decoder(ffp-&gt;pipeline, ffp);
            }
            if (ret || !ffp-&gt;node_vdec) {
                decoder_init(&amp;is-&gt;viddec, avctx, &amp;is-&gt;videoq, is-&gt;continue_read_thread);
                ffp-&gt;node_vdec = ffpipeline_open_video_decoder(ffp-&gt;pipeline, ffp);
                if (!ffp-&gt;node_vdec)
                    goto fail;
            }
        } else {
            //decoder初始化
            decoder_init(&amp;is-&gt;viddec, avctx, &amp;is-&gt;videoq, is-&gt;continue_read_thread);
            ffp-&gt;node_vdec = ffpipeline_open_video_decoder(ffp-&gt;pipeline, ffp);
            if (!ffp-&gt;node_vdec)
                goto fail;
        }
        //解码器开始
        if ((ret = decoder_start(&amp;is-&gt;viddec, video_thread, ffp, &quot;ff_video_dec&quot;)) &lt; 0)
            goto out;

        is-&gt;queue_attachments_req = 1;

        if (ffp-&gt;max_fps &gt;= 0) {
            if(is-&gt;video_st-&gt;avg_frame_rate.den &amp;&amp; is-&gt;video_st-&gt;avg_frame_rate.num) {
                double fps = av_q2d(is-&gt;video_st-&gt;avg_frame_rate);
                SDL_ProfilerReset(&amp;is-&gt;viddec.decode_profiler, fps + 0.5);
                if (fps &gt; ffp-&gt;max_fps &amp;&amp; fps &lt; 130.0) {
                    is-&gt;is_video_high_fps = 1;
                    av_log(ffp, AV_LOG_WARNING, &quot;fps: %lf (too high)\n&quot;, fps);
                } else {
                    av_log(ffp, AV_LOG_WARNING, &quot;fps: %lf (normal)\n&quot;, fps);
                }
            }
            if(is-&gt;video_st-&gt;r_frame_rate.den &amp;&amp; is-&gt;video_st-&gt;r_frame_rate.num) {
                double tbr = av_q2d(is-&gt;video_st-&gt;r_frame_rate);
                if (tbr &gt; ffp-&gt;max_fps &amp;&amp; tbr &lt; 130.0) {
                    is-&gt;is_video_high_fps = 1;
                    av_log(ffp, AV_LOG_WARNING, &quot;fps: %lf (too high)\n&quot;, tbr);
                } else {
                    av_log(ffp, AV_LOG_WARNING, &quot;fps: %lf (normal)\n&quot;, tbr);
                }
            }
        }

        if (is-&gt;is_video_high_fps) {
            avctx-&gt;skip_frame       = FFMAX(avctx-&gt;skip_frame, AVDISCARD_NONREF);
            avctx-&gt;skip_loop_filter = FFMAX(avctx-&gt;skip_loop_filter, AVDISCARD_NONREF);
            avctx-&gt;skip_idct        = FFMAX(avctx-&gt;skip_loop_filter, AVDISCARD_NONREF);
        }

        break;
    case AVMEDIA_TYPE_SUBTITLE:
        if (!ffp-&gt;subtitle) break;

        is-&gt;subtitle_stream = stream_index;
        is-&gt;subtitle_st = ic-&gt;streams[stream_index];

        ffp_set_subtitle_codec_info(ffp, AVCODEC_MODULE_NAME, avcodec_get_name(avctx-&gt;codec_id));

        decoder_init(&amp;is-&gt;subdec, avctx, &amp;is-&gt;subtitleq, is-&gt;continue_read_thread);
        if ((ret = decoder_start(&amp;is-&gt;subdec, subtitle_thread, ffp, &quot;ff_subtitle_dec&quot;)) &lt; 0)
            goto out;
        break;
    default:
        break;
    }
    goto out;

fail:
    avcodec_free_context(&amp;avctx);
out:
    av_dict_free(&amp;opts);

    return ret;
}</code></pre>
<h3 id="小结："><a href="#小结：" class="headerlink" title="小结："></a>小结：</h3><ol>
<li>找到解码器</li>
<li>初始化解码器</li>
<li>分别启动<code>audio_thread</code>，<code>video_thread</code>和<code>subtitle_thread</code>这3条解码线程，内部开始不断解码。</li>
</ol>
<p>那么以下3节则逐个分析这3条解码线程</p>
<h2 id="2-字幕解码线程subtitle-thread"><a href="#2-字幕解码线程subtitle-thread" class="headerlink" title="2 字幕解码线程subtitle_thread"></a>2 字幕解码线程<code>subtitle_thread</code></h2><p>由于字幕解码线程最简单，所以先来看看他是如何工作的，对剩下的两个解码线程就更好理解了。</p>
<pre><code class="c">static int subtitle_thread(void *arg)
{
    FFPlayer *ffp = arg;
    VideoState *is = ffp-&gt;is;
    Frame *sp;
    int got_subtitle;
    double pts;

    for (;;) {
        //阻塞方法，阻塞，直到能取出windex（写下标）下标下的Frame
        if (!(sp = frame_queue_peek_writable(&amp;is-&gt;subpq)))
            return 0;
        //解码，填充Frame中的字幕数据
        if ((got_subtitle = decoder_decode_frame(ffp, &amp;is-&gt;subdec, NULL, &amp;sp-&gt;sub)) &lt; 0)
            break;

        pts = 0;
#ifdef FFP_MERGE
        if (got_subtitle &amp;&amp; sp-&gt;sub.format == 0) {
#else
        if (got_subtitle) {
#endif
            if (sp-&gt;sub.pts != AV_NOPTS_VALUE)
                pts = sp-&gt;sub.pts / (double)AV_TIME_BASE;
            sp-&gt;pts = pts;
            sp-&gt;serial = is-&gt;subdec.pkt_serial;
            sp-&gt;width = is-&gt;subdec.avctx-&gt;width;
            sp-&gt;height = is-&gt;subdec.avctx-&gt;height;
            sp-&gt;uploaded = 0;

            /* now we can update the picture count */
            //后移字幕FrameQueue的windex
            frame_queue_push(&amp;is-&gt;subpq);
#ifdef FFP_MERGE
        } else if (got_subtitle) {
            avsubtitle_free(&amp;sp-&gt;sub);
#endif
        }
    }
    return 0;
}</code></pre>
<p>解码后的数据<code>sp</code>要保存，留着待会渲染，也就是要入队，那么由于<code>FrameQueue</code>是数组的特殊性，因此入队的操作不需要新建的frame数据作为参数，只需要确保数组中的write index的数据正确填充，然后将write index后移一个位置，就称为入队成功了：</p>
<pre><code class="c">static void  frame_queue_push(FrameQueue *f)
{
    //当使用数组作为队列的时候，只需要移动数组中的下标到有效下标，就表示入队了，并不需要外部再传一个参数进来。
    //如果到了尾下标，则windex回到起点。这是用数组作为循环队列的必要操作。
    if (++f-&gt;windex == f-&gt;max_size)
        f-&gt;windex = 0;
    SDL_LockMutex(f-&gt;mutex);
    f-&gt;size++;
    SDL_CondSignal(f-&gt;cond);
    SDL_UnlockMutex(f-&gt;mutex);
}</code></pre>
<p>那么接着来看：<code>decoder_decode_frame（）</code></p>
<p>注意：本文基于0.8.0的ijkplayer，这个函数和以前的ijkplayer的解码逻辑和调用的ffmpeg的函数都有些区别。我看到0.8.0的版本的<code>decoder_decode_frame（）</code>函数的逻辑是在<code>0.8.7</code>的时候修改并上线的。</p>
<h5 id=""><a href="#" class="headerlink" title=""></a></h5><h3 id="2-1-decoder-decode-frame-，since-version-0-8-7"><a href="#2-1-decoder-decode-frame-，since-version-0-8-7" class="headerlink" title="2.1 decoder_decode_frame()，since version 0.8.7"></a>2.1 <code>decoder_decode_frame()</code>，since version 0.8.7</h3><p>先看本文基于的0.8.0的ijkplayer的函数：</p>
<pre><code class="c">static int decoder_decode_frame(FFPlayer *ffp, Decoder *d, AVFrame *frame, AVSubtitle *sub) {
    int ret = AVERROR(EAGAIN);

    for (;;) {
        AVPacket pkt;

        if (d-&gt;queue-&gt;serial == d-&gt;pkt_serial) {
            do {
                if (d-&gt;queue-&gt;abort_request)
                    return -1;

                switch (d-&gt;avctx-&gt;codec_type) {
                    case AVMEDIA_TYPE_VIDEO:
                        //从解码器中接收frame数据。当返回0表示成功
                        ret = avcodec_receive_frame(d-&gt;avctx, frame);
                        if (ret &gt;= 0) {
                            ffp-&gt;stat.vdps = SDL_SpeedSamplerAdd(&amp;ffp-&gt;vdps_sampler, FFP_SHOW_VDPS_AVCODEC, &quot;vdps[avcodec]&quot;);
                            if (ffp-&gt;decoder_reorder_pts == -1) {
                                frame-&gt;pts = frame-&gt;best_effort_timestamp;
                            } else if (!ffp-&gt;decoder_reorder_pts) {
                                frame-&gt;pts = frame-&gt;pkt_dts;
                            }
                        }
                        break;
                    case AVMEDIA_TYPE_AUDIO:
                        //从解码器中接收frame数据。当返回0表示成功
                        ret = avcodec_receive_frame(d-&gt;avctx, frame);
                        if (ret &gt;= 0) {
                            AVRational tb = (AVRational){1, frame-&gt;sample_rate};
                            if (frame-&gt;pts != AV_NOPTS_VALUE)
                                frame-&gt;pts = av_rescale_q(frame-&gt;pts, av_codec_get_pkt_timebase(d-&gt;avctx), tb);
                            else if (d-&gt;next_pts != AV_NOPTS_VALUE)
                                frame-&gt;pts = av_rescale_q(d-&gt;next_pts, d-&gt;next_pts_tb, tb);
                            if (frame-&gt;pts != AV_NOPTS_VALUE) {
                                d-&gt;next_pts = frame-&gt;pts + frame-&gt;nb_samples;
                                d-&gt;next_pts_tb = tb;
                            }
                        }
                        break;
                    default:
                        break;
                }
                if (ret == AVERROR_EOF) {
                    d-&gt;finished = d-&gt;pkt_serial;
                    avcodec_flush_buffers(d-&gt;avctx);
                    return 0;
                }
                //如果返回值&gt;=0，表示avcodec_receive_frame函数解码成功，那么从外部函数decoder_decode_frame返回1。
                //视频，音频，字幕的解码都从这里返回，只要解码成功，都去读取ret然后返回给外面处理。
                if (ret &gt;= 0)
                    return 1;
            } while (ret != AVERROR(EAGAIN));
        }

        do {
            if (d-&gt;queue-&gt;nb_packets == 0)
                SDL_CondSignal(d-&gt;empty_queue_cond);
            if (d-&gt;packet_pending) {
                av_packet_move_ref(&amp;pkt, &amp;d-&gt;pkt);
                d-&gt;packet_pending = 0;
            } else {
                //从packet_queue中取出pkt，当packat_queue由于网络差等原因，没有足够的包可以取出时，则阻塞，直到有包能取出。
                if (packet_queue_get_or_buffering(ffp, d-&gt;queue, &amp;pkt, &amp;d-&gt;pkt_serial, &amp;d-&gt;finished) &lt; 0)
                    return -1;
            }
        } while (d-&gt;queue-&gt;serial != d-&gt;pkt_serial);

        if (pkt.data == flush_pkt.data) {
            avcodec_flush_buffers(d-&gt;avctx);
            d-&gt;finished = 0;
            d-&gt;next_pts = d-&gt;start_pts;
            d-&gt;next_pts_tb = d-&gt;start_pts_tb;
        } else {
            if (d-&gt;avctx-&gt;codec_type == AVMEDIA_TYPE_SUBTITLE) {
                int got_frame = 0;
                //解码字幕
                ret = avcodec_decode_subtitle2(d-&gt;avctx, sub, &amp;got_frame, &amp;pkt);
                if (ret &lt; 0) {
                    ret = AVERROR(EAGAIN);
                } else {
                    if (got_frame &amp;&amp; !pkt.data) {
                       d-&gt;packet_pending = 1;
                       av_packet_move_ref(&amp;d-&gt;pkt, &amp;pkt);
                    }
                    ret = got_frame ? 0 : (pkt.data ? AVERROR(EAGAIN) : AVERROR_EOF);
                }
            } else {
                //往解码器里面发送包数据pkt
                if (avcodec_send_packet(d-&gt;avctx, &amp;pkt) == AVERROR(EAGAIN)) {
                    av_log(d-&gt;avctx, AV_LOG_ERROR, &quot;Receive_frame and send_packet both returned EAGAIN, which is an API violation.\n&quot;);
                    d-&gt;packet_pending = 1;
                    av_packet_move_ref(&amp;d-&gt;pkt, &amp;pkt);
                }
            }
            av_packet_unref(&amp;pkt);
        }
    }
}</code></pre>
<h3 id="2-2-decoder-decode-frame-，before-version-0-8-7"><a href="#2-2-decoder-decode-frame-，before-version-0-8-7" class="headerlink" title="2.2 decoder_decode_frame()，before version 0.8.7"></a>2.2 <code>decoder_decode_frame()</code>，before version 0.8.7</h3><pre><code class="c">static int decoder_decode_frame(FFPlayer *ffp, Decoder *d, AVFrame *frame, AVSubtitle *sub) {
    int got_frame = 0;

    do {
        int ret = -1;

        if (d-&gt;queue-&gt;abort_request)
            return -1;

        if (!d-&gt;packet_pending || d-&gt;queue-&gt;serial != d-&gt;pkt_serial) {
            AVPacket pkt;
            do {
                if (d-&gt;queue-&gt;nb_packets == 0)
                    SDL_CondSignal(d-&gt;empty_queue_cond);
                  //从packet_queue中获取pkt
                if (packet_queue_get_or_buffering(ffp, d-&gt;queue, &amp;pkt, &amp;d-&gt;pkt_serial, &amp;d-&gt;finished) &lt; 0)
                    return -1;
                if (pkt.data == flush_pkt.data) {
                    avcodec_flush_buffers(d-&gt;avctx);
                    d-&gt;finished = 0;
                    d-&gt;next_pts = d-&gt;start_pts;
                    d-&gt;next_pts_tb = d-&gt;start_pts_tb;
                }
            } while (pkt.data == flush_pkt.data || d-&gt;queue-&gt;serial != d-&gt;pkt_serial);
            av_packet_unref(&amp;d-&gt;pkt);
              //将包pkt传递给解码器d
            d-&gt;pkt_temp = d-&gt;pkt = pkt;
            d-&gt;packet_pending = 1;
        }

        switch (d-&gt;avctx-&gt;codec_type) {
            case AVMEDIA_TYPE_VIDEO: {
                  //调用ffmpeg方法：avcodec_deco_video2()来解码。
                ret = avcodec_decode_video2(d-&gt;avctx, frame, &amp;got_frame, &amp;d-&gt;pkt_temp);
                if (got_frame) {
                    ffp-&gt;stat.vdps = SDL_SpeedSamplerAdd(&amp;ffp-&gt;vdps_sampler, FFP_SHOW_VDPS_AVCODEC, &quot;vdps[avcodec]&quot;);
                    if (ffp-&gt;decoder_reorder_pts == -1) {
                        frame-&gt;pts = av_frame_get_best_effort_timestamp(frame);
                    } else if (!ffp-&gt;decoder_reorder_pts) {
                        frame-&gt;pts = frame-&gt;pkt_dts;
                    }
                }
                }
                break;
            case AVMEDIA_TYPE_AUDIO:
                    //调用ffmpeg方法：avcodec_decode_audio4()来解码
                ret = avcodec_decode_audio4(d-&gt;avctx, frame, &amp;got_frame, &amp;d-&gt;pkt_temp);
                if (got_frame) {
                    AVRational tb = (AVRational){1, frame-&gt;sample_rate};
                    if (frame-&gt;pts != AV_NOPTS_VALUE)
                        frame-&gt;pts = av_rescale_q(frame-&gt;pts, av_codec_get_pkt_timebase(d-&gt;avctx), tb);
                    else if (d-&gt;next_pts != AV_NOPTS_VALUE)
                        frame-&gt;pts = av_rescale_q(d-&gt;next_pts, d-&gt;next_pts_tb, tb);
                    if (frame-&gt;pts != AV_NOPTS_VALUE) {
                        d-&gt;next_pts = frame-&gt;pts + frame-&gt;nb_samples;
                        d-&gt;next_pts_tb = tb;
                    }
                }
                break;
            case AVMEDIA_TYPE_SUBTITLE:
                ret = avcodec_decode_subtitle2(d-&gt;avctx, sub, &amp;got_frame, &amp;d-&gt;pkt_temp);
                break;
            default:
                break;
        }

        if (ret &lt; 0) {
            d-&gt;packet_pending = 0;
        } else {
            d-&gt;pkt_temp.dts =
            d-&gt;pkt_temp.pts = AV_NOPTS_VALUE;
            if (d-&gt;pkt_temp.data) {
                if (d-&gt;avctx-&gt;codec_type != AVMEDIA_TYPE_AUDIO)
                    ret = d-&gt;pkt_temp.size;
                d-&gt;pkt_temp.data += ret;
                d-&gt;pkt_temp.size -= ret;
                if (d-&gt;pkt_temp.size &lt;= 0)
                    d-&gt;packet_pending = 0;
            } else {
                if (!got_frame) {
                    d-&gt;packet_pending = 0;
                    d-&gt;finished = d-&gt;pkt_serial;
                }
            }
        }
    } while (!got_frame &amp;&amp; !d-&gt;finished);

    return got_frame;
}</code></pre>
<p>那么再看回到最新的<code>decoder_decode_frame()</code>方法中，首先解码器要从包队列<code>PakcetQueue</code>中读取出包数据，再输送到ffmpeg解码器中。那么这个读取包队列中已经缓存好的包数据的方法是：</p>
<pre><code class="c">static int packet_queue_get_or_buffering(FFPlayer *ffp, PacketQueue *q, AVPacket *pkt, int *serial, int *finished)
{
    assert(finished);
    if (!ffp-&gt;packet_buffering)
        return packet_queue_get(q, pkt, 1, serial);

    while (1) {
        int new_packet = packet_queue_get(q, pkt, 0, serial);
        if (new_packet &lt; 0)
            return -1;
        else if (new_packet == 0) {
            //=0表示no packet，因此要再取
            if (q-&gt;is_buffer_indicator &amp;&amp; !*finished)
                ffp_toggle_buffering(ffp, 1);
            //阻塞，直到从包队列中取出队列头的包，并填充到pkt
            new_packet = packet_queue_get(q, pkt, 1, serial);
            if (new_packet &lt; 0)
                return -1;
        }

        if (*finished == *serial) {
            av_packet_unref(pkt);
            continue;
        }
        else
            break;
    }

    return 1;
}</code></pre>
<p>即读取包pkt是会阻塞的，直到<code>3.6.4</code>章节介绍的视频读取线程读取并解封装包pkt，并放入<code>PacketQueue</code>，这里才能从阻塞返回并继续塞给解码器。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ol>
<li><p>0.8.7开始，<code>decode_decode_frame()</code>函数借助ffmpeg的两个方法来完成解码：</p>
<ol>
<li><code>int avcodec_send_packet(AVCodecContex* *avctx, const AVPacket *avpkt);</code>往解码器里面发送pkt数据。</li>
<li><code>int avcodec_receive_frame(AVCodecContext *avctx, AVFrame *frame);</code>从解码器里面读取出frame帧数据。</li>
</ol>
</li>
<li><p>而在0.8.7之前，音频和视频的解码都各自分别使用一个不同的解码函数：</p>
<ol>
<li><p>视频：</p>
<pre><code class="c">//已被废弃
int avcodec_decode_video2(AVCodecContext *avctx, AVFrame *picture,
                         int *got_picture_ptr,
                         const AVPacket *avpkt);</code></pre>
</li>
<li><p>音频：</p>
<pre><code class="c">//已被废弃
int avcodec_decode_audio4(AVCodecContext *avctx, AVFrame *frame,
                          int *got_frame_ptr, const AVPacket *avpkt)</code></pre>
</li>
</ol>
</li>
<li><p>解码字幕的函数：</p>
<pre><code class="c">int avcodec_decode_subtitle2(AVCodecContext *avctx, AVSubtitle *sub,
                            int *got_sub_ptr,
                            AVPacket *avpkt);</code></pre>
</li>
<li><p>从字幕的解码流程中可以看出解码的大致逻辑为：</p>
<ol>
<li>循环地调用<code>decoder_decode_frame（）</code>，在这个方法里面对视频，音频和字幕3种流用switch语句来分别处理解码。当然，在音频解码<code>audio_thread</code>和视频解码<code>video_thread</code>中同样会调用这个方法的。</li>
<li>解码前，先从<code>PacketQueue</code>读取包数据，这个数据从哪里来？从<code>read_thread()</code>函数中调用的ffmpeg的函数：<code>av_read_frame(ic, pkt);</code>来的。</li>
<li>解码时，先塞给解码器pkt数据，再从解码器中读出解码好的frame数据。</li>
<li>再把frame数据入队<code>FrameQueue</code>，留给稍后的渲染器来从<code>FrameQueue</code>中读取 </li>
</ol>
</li>
</ol>
<h2 id="3-音频解码线程audio-thread"><a href="#3-音频解码线程audio-thread" class="headerlink" title="3 音频解码线程audio_thread"></a>3 音频解码线程<code>audio_thread</code></h2><pre><code class="c">static int audio_thread(void *arg)
{
    FFPlayer *ffp = arg;
    VideoState *is = ffp-&gt;is;
    AVFrame *frame = av_frame_alloc();//分配一个AVFrame
    Frame *af;//从FrameQueue sampq中取出来的，要写入数据的Frame
#if CONFIG_AVFILTER
    int last_serial = -1;
    int64_t dec_channel_layout;
    int reconfigure;
#endif
    int got_frame = 0;
    AVRational tb;//分子分母对(ffmpeg为了准确性和避免转换，定义了一个分子分母对来取代float)
    int ret = 0;
    int audio_accurate_seek_fail = 0;
    int64_t audio_seek_pos = 0;
    double frame_pts = 0;
    double audio_clock = 0;
    int64_t now = 0;
    double samples_duration = 0;
    int64_t deviation = 0;
    int64_t deviation2 = 0;
    int64_t deviation3 = 0;

    if (!frame)
        return AVERROR(ENOMEM);

    do {
        ffp_audio_statistic_l(ffp);
        //音频解码
        if ((got_frame = decoder_decode_frame(ffp, &amp;is-&gt;auddec, frame, NULL)) &lt; 0)
            goto the_end;
        //当解码成功
        if (got_frame) {
                tb = (AVRational){1, frame-&gt;sample_rate};
                //处理accurate_seek
                if (ffp-&gt;enable_accurate_seek &amp;&amp; is-&gt;audio_accurate_seek_req &amp;&amp; !is-&gt;seek_req) {
                    frame_pts = (frame-&gt;pts == AV_NOPTS_VALUE) ? NAN : frame-&gt;pts * av_q2d(tb);
                    now = av_gettime_relative() / 1000;
                    if (!isnan(frame_pts)) {
                        samples_duration = (double) frame-&gt;nb_samples / frame-&gt;sample_rate;
                        audio_clock = frame_pts + samples_duration;
                        is-&gt;accurate_seek_aframe_pts = audio_clock * 1000 * 1000;
                        audio_seek_pos = is-&gt;seek_pos;
                        deviation = llabs((int64_t)(audio_clock * 1000 * 1000) - is-&gt;seek_pos);
                        if ((audio_clock * 1000 * 1000 &lt; is-&gt;seek_pos ) || deviation &gt; MAX_DEVIATION) {
                            if (is-&gt;drop_aframe_count == 0) {
                                SDL_LockMutex(is-&gt;accurate_seek_mutex);
                                if (is-&gt;accurate_seek_start_time &lt;= 0 &amp;&amp; (is-&gt;video_stream &lt; 0 || is-&gt;video_accurate_seek_req)) {
                                    is-&gt;accurate_seek_start_time = now;
                                }
                                SDL_UnlockMutex(is-&gt;accurate_seek_mutex);
                                av_log(NULL, AV_LOG_INFO, &quot;audio accurate_seek start, is-&gt;seek_pos=%lld, audio_clock=%lf, is-&gt;accurate_seek_start_time = %lld\n&quot;, is-&gt;seek_pos, audio_clock, is-&gt;accurate_seek_start_time);
                            }
                            is-&gt;drop_aframe_count++;
                            while (is-&gt;video_accurate_seek_req &amp;&amp; !is-&gt;abort_request) {
                                int64_t vpts = is-&gt;accurate_seek_vframe_pts;
                                deviation2 = vpts  - audio_clock * 1000 * 1000;
                                deviation3 = vpts  - is-&gt;seek_pos;
                                if (deviation2 &gt; -100 * 1000 &amp;&amp; deviation3 &lt; 0) {

                                    break;
                                } else {
                                    av_usleep(20 * 1000);
                                }
                                now = av_gettime_relative() / 1000;
                                if ((now - is-&gt;accurate_seek_start_time) &gt; ffp-&gt;accurate_seek_timeout) {
                                    break;
                                }
                            }

                            if(!is-&gt;video_accurate_seek_req &amp;&amp; is-&gt;video_stream &gt;= 0 &amp;&amp; audio_clock * 1000 * 1000 &gt; is-&gt;accurate_seek_vframe_pts) {
                                audio_accurate_seek_fail = 1;
                            } else {
                                now = av_gettime_relative() / 1000;
                                if ((now - is-&gt;accurate_seek_start_time) &lt;= ffp-&gt;accurate_seek_timeout) {
                                    av_frame_unref(frame);
                                    continue;  // drop some old frame when do accurate seek
                                } else {
                                    audio_accurate_seek_fail = 1;
                                }
                            }
                        } else {
                            if (audio_seek_pos == is-&gt;seek_pos) {
                                av_log(NULL, AV_LOG_INFO, &quot;audio accurate_seek is ok, is-&gt;drop_aframe_count=%d, audio_clock = %lf\n&quot;, is-&gt;drop_aframe_count, audio_clock);
                                is-&gt;drop_aframe_count       = 0;
                                SDL_LockMutex(is-&gt;accurate_seek_mutex);
                                is-&gt;audio_accurate_seek_req = 0;
                                SDL_CondSignal(is-&gt;video_accurate_seek_cond);
                                if (audio_seek_pos == is-&gt;seek_pos &amp;&amp; is-&gt;video_accurate_seek_req &amp;&amp; !is-&gt;abort_request) {
                                    SDL_CondWaitTimeout(is-&gt;audio_accurate_seek_cond, is-&gt;accurate_seek_mutex, ffp-&gt;accurate_seek_timeout);
                                } else {
                                    ffp_notify_msg2(ffp, FFP_MSG_ACCURATE_SEEK_COMPLETE, (int)(audio_clock * 1000));
                                }

                                if (audio_seek_pos != is-&gt;seek_pos &amp;&amp; !is-&gt;abort_request) {
                                    is-&gt;audio_accurate_seek_req = 1;
                                    SDL_UnlockMutex(is-&gt;accurate_seek_mutex);
                                    av_frame_unref(frame);
                                    continue;
                                }

                                SDL_UnlockMutex(is-&gt;accurate_seek_mutex);
                            }
                        }
                    } else {
                        audio_accurate_seek_fail = 1;
                    }
                    if (audio_accurate_seek_fail) {
                        av_log(NULL, AV_LOG_INFO, &quot;audio accurate_seek is error, is-&gt;drop_aframe_count=%d, now = %lld, audio_clock = %lf\n&quot;, is-&gt;drop_aframe_count, now, audio_clock);
                        is-&gt;drop_aframe_count       = 0;
                        SDL_LockMutex(is-&gt;accurate_seek_mutex);
                        is-&gt;audio_accurate_seek_req = 0;
                        SDL_CondSignal(is-&gt;video_accurate_seek_cond);
                        if (is-&gt;video_accurate_seek_req &amp;&amp; !is-&gt;abort_request) {
                            SDL_CondWaitTimeout(is-&gt;audio_accurate_seek_cond, is-&gt;accurate_seek_mutex, ffp-&gt;accurate_seek_timeout);
                        } else {
                            ffp_notify_msg2(ffp, FFP_MSG_ACCURATE_SEEK_COMPLETE, (int)(audio_clock * 1000));
                        }
                        SDL_UnlockMutex(is-&gt;accurate_seek_mutex);
                    }
                    is-&gt;accurate_seek_start_time = 0;
                    audio_accurate_seek_fail = 0;
                }

#if CONFIG_AVFILTER
                dec_channel_layout = get_valid_channel_layout(frame-&gt;channel_layout, frame-&gt;channels);

                reconfigure =
                    cmp_audio_fmts(is-&gt;audio_filter_src.fmt, is-&gt;audio_filter_src.channels,
                                   frame-&gt;format, frame-&gt;channels)    ||
                    is-&gt;audio_filter_src.channel_layout != dec_channel_layout ||
                    is-&gt;audio_filter_src.freq           != frame-&gt;sample_rate ||
                    is-&gt;auddec.pkt_serial               != last_serial        ||
                    ffp-&gt;af_changed;

                if (reconfigure) {
                    SDL_LockMutex(ffp-&gt;af_mutex);
                    ffp-&gt;af_changed = 0;
                    char buf1[1024], buf2[1024];
                    av_get_channel_layout_string(buf1, sizeof(buf1), -1, is-&gt;audio_filter_src.channel_layout);
                    av_get_channel_layout_string(buf2, sizeof(buf2), -1, dec_channel_layout);
                    av_log(NULL, AV_LOG_DEBUG,
                           &quot;Audio frame changed from rate:%d ch:%d fmt:%s layout:%s serial:%d to rate:%d ch:%d fmt:%s layout:%s serial:%d\n&quot;,
                           is-&gt;audio_filter_src.freq, is-&gt;audio_filter_src.channels, av_get_sample_fmt_name(is-&gt;audio_filter_src.fmt), buf1, last_serial,
                           frame-&gt;sample_rate, frame-&gt;channels, av_get_sample_fmt_name(frame-&gt;format), buf2, is-&gt;auddec.pkt_serial);

                    is-&gt;audio_filter_src.fmt            = frame-&gt;format;
                    is-&gt;audio_filter_src.channels       = frame-&gt;channels;
                    is-&gt;audio_filter_src.channel_layout = dec_channel_layout;
                    is-&gt;audio_filter_src.freq           = frame-&gt;sample_rate;
                    last_serial                         = is-&gt;auddec.pkt_serial;

                    if ((ret = configure_audio_filters(ffp, ffp-&gt;afilters, 1)) &lt; 0) {
                        SDL_UnlockMutex(ffp-&gt;af_mutex);
                        goto the_end;
                    }
                    SDL_UnlockMutex(ffp-&gt;af_mutex);
                }

            if ((ret = av_buffersrc_add_frame(is-&gt;in_audio_filter, frame)) &lt; 0)
                goto the_end;

            while ((ret = av_buffersink_get_frame_flags(is-&gt;out_audio_filter, frame, 0)) &gt;= 0) {
                tb = av_buffersink_get_time_base(is-&gt;out_audio_filter);
#endif
                if (!(af = frame_queue_peek_writable(&amp;is-&gt;sampq)))//如果sampq无法写入，则失败
                    goto the_end;

                af-&gt;pts = (frame-&gt;pts == AV_NOPTS_VALUE) ? NAN : frame-&gt;pts * av_q2d(tb);
                af-&gt;pos = frame-&gt;pkt_pos;
                af-&gt;serial = is-&gt;auddec.pkt_serial;
                af-&gt;duration = av_q2d((AVRational){frame-&gt;nb_samples, frame-&gt;sample_rate});
                //Move everything contained in src to dst and reset src.将解码出来的AVFrame传给af-&gt;frame
                av_frame_move_ref(af-&gt;frame, frame);
                //将af-&gt;frame入队
                frame_queue_push(&amp;is-&gt;sampq);

#if CONFIG_AVFILTER
                if (is-&gt;audioq.serial != is-&gt;auddec.pkt_serial)
                    break;
            }
            if (ret == AVERROR_EOF)
                is-&gt;auddec.finished = is-&gt;auddec.pkt_serial;
#endif
        }
    } while (ret &gt;= 0 || ret == AVERROR(EAGAIN) || ret == AVERROR_EOF);
 the_end:
#if CONFIG_AVFILTER
    avfilter_graph_free(&amp;is-&gt;agraph);
#endif
    av_frame_free(&amp;frame);
    return ret;
}</code></pre>
<p>音频解码这里暂时不去分析解码之后的seek操作，所以和字幕解码没什么差别，没什么好分析的。</p>
<h2 id="4-视频解码线程video-thread"><a href="#4-视频解码线程video-thread" class="headerlink" title="4 视频解码线程video_thread"></a>4 视频解码线程<code>video_thread</code></h2><p>终于来到视频解码了…</p>
<pre><code class="c">static int video_thread(void *arg)
{
    FFPlayer *ffp = (FFPlayer *)arg;
    int       ret = 0;
        //如果node_vdec不为null。
    if (ffp-&gt;node_vdec) {
          //调用解码器的解码方法，进入循环
        ret = ffpipenode_run_sync(ffp-&gt;node_vdec);
    }
    return ret;
}</code></pre>
<p>最后是走到了<code>IJKFF_Pipenode</code>的<code>func_run_sync()</code>函数中</p>
<pre><code class="c">static int ffplay_video_thread(void *arg)
{
    FFPlayer *ffp = arg;
    VideoState *is = ffp-&gt;is;
    AVFrame *frame = av_frame_alloc();//创建一个新的AVFrame
    double pts;
    double duration;
    int ret;
    AVRational tb = is-&gt;video_st-&gt;time_base;
    AVRational frame_rate = av_guess_frame_rate(is-&gt;ic, is-&gt;video_st, NULL);
    int64_t dst_pts = -1;
    int64_t last_dst_pts = -1;
    int retry_convert_image = 0;
    int convert_frame_count = 0;

#if CONFIG_AVFILTER
    AVFilterGraph *graph = avfilter_graph_alloc();
    AVFilterContext *filt_out = NULL, *filt_in = NULL;
    int last_w = 0;
    int last_h = 0;
    enum AVPixelFormat last_format = -2;
    int last_serial = -1;
    int last_vfilter_idx = 0;
    if (!graph) {
        av_frame_free(&amp;frame);
        return AVERROR(ENOMEM);
    }

#else
    ffp_notify_msg2(ffp, FFP_MSG_VIDEO_ROTATION_CHANGED, ffp_get_video_rotate_degrees(ffp));
#endif

    if (!frame) {
#if CONFIG_AVFILTER
        avfilter_graph_free(&amp;graph);
#endif
        return AVERROR(ENOMEM);
    }
    //开启无限循环，无限地去从packet_queue中拿取pkt来解码。
    for (;;) {
        ret = get_video_frame(ffp, frame);//解码，并将解码后的帧数据存放在frame中
        if (ret &lt; 0)
            goto the_end;
        if (!ret)
            continue;

        if (ffp-&gt;get_frame_mode) {
            if (!ffp-&gt;get_img_info || ffp-&gt;get_img_info-&gt;count &lt;= 0) {
                av_frame_unref(frame);
                continue;
            }

            last_dst_pts = dst_pts;

            if (dst_pts &lt; 0) {
                dst_pts = ffp-&gt;get_img_info-&gt;start_time;
            } else {
                dst_pts += (ffp-&gt;get_img_info-&gt;end_time - ffp-&gt;get_img_info-&gt;start_time) / (ffp-&gt;get_img_info-&gt;num - 1);
            }

            pts = (frame-&gt;pts == AV_NOPTS_VALUE) ? NAN : frame-&gt;pts * av_q2d(tb);
            pts = pts * 1000;
            if (pts &gt;= dst_pts) {
                while (retry_convert_image &lt;= MAX_RETRY_CONVERT_IMAGE) {
                    ret = convert_image(ffp, frame, (int64_t)pts, frame-&gt;width, frame-&gt;height);
                    if (!ret) {
                        convert_frame_count++;
                        break;
                    }
                    retry_convert_image++;
                    av_log(NULL, AV_LOG_ERROR, &quot;convert image error retry_convert_image = %d\n&quot;, retry_convert_image);
                }

                retry_convert_image = 0;
                if (ret || ffp-&gt;get_img_info-&gt;count &lt;= 0) {
                    if (ret) {
                        av_log(NULL, AV_LOG_ERROR, &quot;convert image abort ret = %d\n&quot;, ret);
                        ffp_notify_msg3(ffp, FFP_MSG_GET_IMG_STATE, 0, ret);
                    } else {
                        av_log(NULL, AV_LOG_INFO, &quot;convert image complete convert_frame_count = %d\n&quot;, convert_frame_count);
                    }
                    goto the_end;
                }
            } else {
                dst_pts = last_dst_pts;
            }
            av_frame_unref(frame);
            continue;
        }

//省略了AV_FILTER部分的代码
            duration = (frame_rate.num &amp;&amp; frame_rate.den ? av_q2d((AVRational){frame_rate.den, frame_rate.num}) : 0);
            pts = (frame-&gt;pts == AV_NOPTS_VALUE) ? NAN : frame-&gt;pts * av_q2d(tb);
            //将frame入队到pictq中，来让渲染线程读取。
            ret = queue_picture(ffp, frame, pts, duration, frame-&gt;pkt_pos, is-&gt;viddec.pkt_serial);
            av_frame_unref(frame);

        if (ret &lt; 0)
            goto the_end;
    }
 the_end:
#if CONFIG_AVFILTER
    avfilter_graph_free(&amp;graph);
#endif
    av_log(NULL, AV_LOG_INFO, &quot;convert image convert_frame_count = %d\n&quot;, convert_frame_count);
    av_frame_free(&amp;frame);
    return 0;
}</code></pre>
<p>简略为：</p>
<pre><code class="c">static int ffplay_video_thread(void *arg){
  for(;;){
    ret = get_video_frame(ffp, frame);//解码，并将解码后的帧数据存放在frame中
    //将frame入队到pictq中，来让渲染线程读取。
    ret = queue_picture(ffp, frame, pts, duration, frame-&gt;pkt_pos, is-&gt;viddec.pkt_serial);
  }
}</code></pre>
<p>那么看下解码函数：</p>
<pre><code class="c">static int get_video_frame(FFPlayer *ffp, AVFrame *frame)
{
    VideoState *is = ffp-&gt;is;
    int got_picture;

    ffp_video_statistic_l(ffp);
    //解码，并将视频帧数据填充到frame中，可能阻塞
    if ((got_picture = decoder_decode_frame(ffp, &amp;is-&gt;viddec, frame, NULL)) &lt; 0)
        return -1;

    if (got_picture) {
        double dpts = NAN;

        if (frame-&gt;pts != AV_NOPTS_VALUE)
            dpts = av_q2d(is-&gt;video_st-&gt;time_base) * frame-&gt;pts;

        frame-&gt;sample_aspect_ratio = av_guess_sample_aspect_ratio(is-&gt;ic, is-&gt;video_st, frame);

        if (ffp-&gt;framedrop&gt;0 || (ffp-&gt;framedrop &amp;&amp; get_master_sync_type(is) != AV_SYNC_VIDEO_MASTER)) {
            ffp-&gt;stat.decode_frame_count++;
            if (frame-&gt;pts != AV_NOPTS_VALUE) {
                double diff = dpts - get_master_clock(is);
                if (!isnan(diff) &amp;&amp; fabs(diff) &lt; AV_NOSYNC_THRESHOLD &amp;&amp;
                    diff - is-&gt;frame_last_filter_delay &lt; 0 &amp;&amp;
                    is-&gt;viddec.pkt_serial == is-&gt;vidclk.serial &amp;&amp;
                    is-&gt;videoq.nb_packets) {
                    is-&gt;frame_drops_early++;
                    is-&gt;continuous_frame_drops_early++;
                    if (is-&gt;continuous_frame_drops_early &gt; ffp-&gt;framedrop) {
                        is-&gt;continuous_frame_drops_early = 0;
                    } else {
                        ffp-&gt;stat.drop_frame_count++;
                        ffp-&gt;stat.drop_frame_rate = (float)(ffp-&gt;stat.drop_frame_count) / (float)(ffp-&gt;stat.decode_frame_count);
                        av_frame_unref(frame);
                        got_picture = 0;
                    }
                }
            }
        }
    }

    return got_picture;
}</code></pre>
<p>那么这里又是用的和字幕解码、音频解码一样的解码函数：<code>decoder_decode_frame</code>，就不重复提了。</p>
<pre><code class="c">//将src_frame入队到picq中，让渲染线程渲染。
static int queue_picture(FFPlayer *ffp, AVFrame *src_frame, double pts, double duration, int64_t pos, int serial)
{
    VideoState *is = ffp-&gt;is;
    Frame *vp;
    int video_accurate_seek_fail = 0;
    int64_t video_seek_pos = 0;
    int64_t now = 0;
    int64_t deviation = 0;

    int64_t deviation2 = 0;
    int64_t deviation3 = 0;
    //处理精确seek
    if (ffp-&gt;enable_accurate_seek &amp;&amp; is-&gt;video_accurate_seek_req &amp;&amp; !is-&gt;seek_req) {
        if (!isnan(pts)) {
            video_seek_pos = is-&gt;seek_pos;
            is-&gt;accurate_seek_vframe_pts = pts * 1000 * 1000;
            deviation = llabs((int64_t)(pts * 1000 * 1000) - is-&gt;seek_pos);
            if ((pts * 1000 * 1000 &lt; is-&gt;seek_pos) || deviation &gt; MAX_DEVIATION) {
                now = av_gettime_relative() / 1000;
                if (is-&gt;drop_vframe_count == 0) {
                    SDL_LockMutex(is-&gt;accurate_seek_mutex);
                    if (is-&gt;accurate_seek_start_time &lt;= 0 &amp;&amp; (is-&gt;audio_stream &lt; 0 || is-&gt;audio_accurate_seek_req)) {
                        is-&gt;accurate_seek_start_time = now;
                    }
                    SDL_UnlockMutex(is-&gt;accurate_seek_mutex);
                    av_log(NULL, AV_LOG_INFO, &quot;video accurate_seek start, is-&gt;seek_pos=%lld, pts=%lf, is-&gt;accurate_seek_time = %lld\n&quot;, is-&gt;seek_pos, pts, is-&gt;accurate_seek_start_time);
                }
                is-&gt;drop_vframe_count++;

                while (is-&gt;audio_accurate_seek_req &amp;&amp; !is-&gt;abort_request) {
                    int64_t apts = is-&gt;accurate_seek_aframe_pts ;
                    deviation2 = apts - pts * 1000 * 1000;
                    deviation3 = apts - is-&gt;seek_pos;

                    if (deviation2 &gt; -100 * 1000 &amp;&amp; deviation3 &lt; 0) {
                        break;
                    } else {
                        av_usleep(20 * 1000);
                    }
                    now = av_gettime_relative() / 1000;
                    if ((now - is-&gt;accurate_seek_start_time) &gt; ffp-&gt;accurate_seek_timeout) {
                        break;
                    }
                }

                if ((now - is-&gt;accurate_seek_start_time) &lt;= ffp-&gt;accurate_seek_timeout) {
                    return 1;  // drop some old frame when do accurate seek
                } else {
                    av_log(NULL, AV_LOG_WARNING, &quot;video accurate_seek is error, is-&gt;drop_vframe_count=%d, now = %lld, pts = %lf\n&quot;, is-&gt;drop_vframe_count, now, pts);
                    video_accurate_seek_fail = 1;  // if KEY_FRAME interval too big, disable accurate seek
                }
            } else {
                av_log(NULL, AV_LOG_INFO, &quot;video accurate_seek is ok, is-&gt;drop_vframe_count =%d, is-&gt;seek_pos=%lld, pts=%lf\n&quot;, is-&gt;drop_vframe_count, is-&gt;seek_pos, pts);
                if (video_seek_pos == is-&gt;seek_pos) {
                    is-&gt;drop_vframe_count       = 0;
                    SDL_LockMutex(is-&gt;accurate_seek_mutex);
                    is-&gt;video_accurate_seek_req = 0;
                    SDL_CondSignal(is-&gt;audio_accurate_seek_cond);
                    if (video_seek_pos == is-&gt;seek_pos &amp;&amp; is-&gt;audio_accurate_seek_req &amp;&amp; !is-&gt;abort_request) {
                        SDL_CondWaitTimeout(is-&gt;video_accurate_seek_cond, is-&gt;accurate_seek_mutex, ffp-&gt;accurate_seek_timeout);
                    } else {
                        ffp_notify_msg2(ffp, FFP_MSG_ACCURATE_SEEK_COMPLETE, (int)(pts * 1000));
                    }
                    if (video_seek_pos != is-&gt;seek_pos &amp;&amp; !is-&gt;abort_request) {
                        is-&gt;video_accurate_seek_req = 1;
                        SDL_UnlockMutex(is-&gt;accurate_seek_mutex);
                        return 1;
                    }

                    SDL_UnlockMutex(is-&gt;accurate_seek_mutex);
                }
            }
        } else {
            video_accurate_seek_fail = 1;
        }

        if (video_accurate_seek_fail) {
            is-&gt;drop_vframe_count = 0;
            SDL_LockMutex(is-&gt;accurate_seek_mutex);
            is-&gt;video_accurate_seek_req = 0;
            SDL_CondSignal(is-&gt;audio_accurate_seek_cond);
            if (is-&gt;audio_accurate_seek_req &amp;&amp; !is-&gt;abort_request) {
                SDL_CondWaitTimeout(is-&gt;video_accurate_seek_cond, is-&gt;accurate_seek_mutex, ffp-&gt;accurate_seek_timeout);
            } else {
                if (!isnan(pts)) {
                    ffp_notify_msg2(ffp, FFP_MSG_ACCURATE_SEEK_COMPLETE, (int)(pts * 1000));
                } else {
                    ffp_notify_msg2(ffp, FFP_MSG_ACCURATE_SEEK_COMPLETE, 0);
                }
            }
            SDL_UnlockMutex(is-&gt;accurate_seek_mutex);
        }
        is-&gt;accurate_seek_start_time = 0;
        video_accurate_seek_fail = 0;
        is-&gt;accurate_seek_vframe_pts = 0;
    }

#if defined(DEBUG_SYNC)
    printf(&quot;frame_type=%c pts=%0.3f\n&quot;,
           av_get_picture_type_char(src_frame-&gt;pict_type), pts);
#endif

    if (!(vp = frame_queue_peek_writable(&amp;is-&gt;pictq)))
        return -1;

    vp-&gt;sar = src_frame-&gt;sample_aspect_ratio;
#ifdef FFP_MERGE
    vp-&gt;uploaded = 0;
#endif

    /* alloc or resize hardware picture buffer */
    if (!vp-&gt;bmp || !vp-&gt;allocated ||
        vp-&gt;width  != src_frame-&gt;width ||
        vp-&gt;height != src_frame-&gt;height ||
        vp-&gt;format != src_frame-&gt;format) {

        if (vp-&gt;width != src_frame-&gt;width || vp-&gt;height != src_frame-&gt;height)
            ffp_notify_msg3(ffp, FFP_MSG_VIDEO_SIZE_CHANGED, src_frame-&gt;width, src_frame-&gt;height);

        vp-&gt;allocated = 0;
        vp-&gt;width = src_frame-&gt;width;
        vp-&gt;height = src_frame-&gt;height;
        vp-&gt;format = src_frame-&gt;format;

        /* the allocation must be done in the main thread to avoid
           locking problems. */
        alloc_picture(ffp, src_frame-&gt;format);

        if (is-&gt;videoq.abort_request)
            return -1;
    }

    /* if the frame is not skipped, then display it */
    if (vp-&gt;bmp) {
        /* get a pointer on the bitmap */
        SDL_VoutLockYUVOverlay(vp-&gt;bmp);//加锁

#ifdef FFP_MERGE
#if CONFIG_AVFILTER
        // FIXME use direct rendering
        av_image_copy(data, linesize, (const uint8_t **)src_frame-&gt;data, src_frame-&gt;linesize,
                        src_frame-&gt;format, vp-&gt;width, vp-&gt;height);
#else
        // sws_getCachedContext(...);
#endif
#endif
        // FIXME: set swscale options
        //将src_frame中的帧数据填充到vp-&gt;bmp中，这个vp-&gt;bmp其实指的是bitmap？
        if (SDL_VoutFillFrameYUVOverlay(vp-&gt;bmp, src_frame) &lt; 0) {
            av_log(NULL, AV_LOG_FATAL, &quot;Cannot initialize the conversion context\n&quot;);
            exit(1);
        }
        /* update the bitmap content */
        SDL_VoutUnlockYUVOverlay(vp-&gt;bmp);//解锁

        vp-&gt;pts = pts;
        vp-&gt;duration = duration;
        vp-&gt;pos = pos;
        vp-&gt;serial = serial;
        vp-&gt;sar = src_frame-&gt;sample_aspect_ratio;
        vp-&gt;bmp-&gt;sar_num = vp-&gt;sar.num;
        vp-&gt;bmp-&gt;sar_den = vp-&gt;sar.den;

#ifdef FFP_MERGE
        av_frame_move_ref(vp-&gt;frame, src_frame);
#endif
        frame_queue_push(&amp;is-&gt;pictq);
        if (!is-&gt;viddec.first_frame_decoded) {
            ALOGD(&quot;Video: first frame decoded\n&quot;);
            ffp_notify_msg1(ffp, FFP_MSG_VIDEO_DECODED_START);
            is-&gt;viddec.first_frame_decoded_time = SDL_GetTickHR();
            is-&gt;viddec.first_frame_decoded = 1;
        }
    }
    return 0;
}</code></pre>
<p>这里重点看下将frame数据填充到vp-&gt;bmp数据中的这个操作。</p>
<p>bmp长得非常像bitmap，看来意思是将帧数据填充到图像数据中的意思了。</p>
<pre><code class="c">int SDL_VoutFillFrameYUVOverlay(SDL_VoutOverlay *overlay, const AVFrame *frame)
{
    if (!overlay || !overlay-&gt;func_fill_frame)
        return -1;

    return overlay-&gt;func_fill_frame(overlay, frame);
}</code></pre>
<pre><code class="c">static int func_fill_frame(SDL_VoutOverlay *overlay, const AVFrame *frame){
    //...
    overlay_fill(overlay, opaque-&gt;linked_frame, opaque-&gt;planes);
    //...
}

static void overlay_fill(SDL_VoutOverlay *overlay, AVFrame *frame, int planes)
{
    overlay-&gt;planes = planes;

    for (int i = 0; i &lt; AV_NUM_DATA_POINTERS; ++i) {
        //数组的复制 
        overlay-&gt;pixels[i] = frame-&gt;data[i];
        overlay-&gt;pitches[i] = frame-&gt;linesize[i];
    }
}</code></pre>
<p>那么到这里，应该是将<code>AVFrame</code>中的数据全部复制到这个<code>vp-&gt;bmp</code>中了，而他是：<code>*SDL_VoutOverlay*</code></p>
<h2 id="5-视频渲染线程"><a href="#5-视频渲染线程" class="headerlink" title="5 视频渲染线程"></a>5 视频渲染线程</h2><pre><code class="c">//创建视频刷新线程
is-&gt;video_refresh_tid = SDL_CreateThreadEx(&amp;is-&gt;_video_refresh_tid, video_refresh_thread, ffp, &quot;ff_vout&quot;);</code></pre>
<p>创建一个线程专门用于渲染视频。在看代码之前，先了解一下视频渲染要做什么：</p>
<ol>
<li>从<code>FrameQueue</code>中拿取每一帧解码完的原始图像帧数据。</li>
<li>将帧数据发送到显示设备，让对应设备将图像数据画出来。</li>
<li>这是一个循环的过程，解码线程不断解码出图像帧，这边的渲染线程不断地读取图像帧并输送到渲染设备。</li>
</ol>
<pre><code class="c">//    ijkmedia/ijkplayer/ff_ffplay.c
static int video_refresh_thread(void *arg)
{
    FFPlayer *ffp = arg;
    VideoState *is = ffp-&gt;is;
    double remaining_time = 0.0;
      //循环，如果没有中断请求，那么就一直尝试去渲染。
    while (!is-&gt;abort_request) {
        if (remaining_time &gt; 0.0)
            av_usleep((int)(int64_t)(remaining_time * 1000000.0));
        remaining_time = REFRESH_RATE;
        if (is-&gt;show_mode != SHOW_MODE_NONE &amp;&amp; (!is-&gt;paused || is-&gt;force_refresh))
              //刷新视频
            video_refresh(ffp, &amp;remaining_time);
    }

    return 0;
}</code></pre>
<pre><code class="c">//    ijkmedia/ijkplayer/ff_ffplay.c

/* called to display each frame */
static void video_refresh(FFPlayer *opaque, double *remaining_time)
{
    FFPlayer *ffp = opaque;
    VideoState *is = ffp-&gt;is;
    double time;

    Frame *sp, *sp2;
    //处理时钟。
    if (!is-&gt;paused &amp;&amp; get_master_sync_type(is) == AV_SYNC_EXTERNAL_CLOCK &amp;&amp; is-&gt;realtime)
        check_external_clock_speed(is);

    if (!ffp-&gt;display_disable &amp;&amp; is-&gt;show_mode != SHOW_MODE_VIDEO &amp;&amp; is-&gt;audio_st) {
        time = av_gettime_relative() / 1000000.0;
        if (is-&gt;force_refresh || is-&gt;last_vis_time + ffp-&gt;rdftspeed &lt; time) {
            //①
            video_display2(ffp);
            is-&gt;last_vis_time = time;
        }
        *remaining_time = FFMIN(*remaining_time, is-&gt;last_vis_time + ffp-&gt;rdftspeed - time);
    }

    if (is-&gt;video_st) {
retry:
        if (frame_queue_nb_remaining(&amp;is-&gt;pictq) == 0) {
            // nothing to do, no picture to display in the queue
        } else {
            double last_duration, duration, delay;
            Frame *vp, *lastvp;

            /* dequeue the picture */
            lastvp = frame_queue_peek_last(&amp;is-&gt;pictq);
            vp = frame_queue_peek(&amp;is-&gt;pictq);

            if (vp-&gt;serial != is-&gt;videoq.serial) {
                frame_queue_next(&amp;is-&gt;pictq);
                goto retry;
            }

            if (lastvp-&gt;serial != vp-&gt;serial)
                is-&gt;frame_timer = av_gettime_relative() / 1000000.0;

            if (is-&gt;paused)
                goto display;

            /* compute nominal last_duration */
            last_duration = vp_duration(is, lastvp, vp);
            delay = compute_target_delay(ffp, last_duration, is);

            time= av_gettime_relative()/1000000.0;
            if (isnan(is-&gt;frame_timer) || time &lt; is-&gt;frame_timer)
                is-&gt;frame_timer = time;
            if (time &lt; is-&gt;frame_timer + delay) {
                *remaining_time = FFMIN(is-&gt;frame_timer + delay - time, *remaining_time);
                goto display;
            }

            is-&gt;frame_timer += delay;
            if (delay &gt; 0 &amp;&amp; time - is-&gt;frame_timer &gt; AV_SYNC_THRESHOLD_MAX)
                is-&gt;frame_timer = time;

            SDL_LockMutex(is-&gt;pictq.mutex);
            if (!isnan(vp-&gt;pts))
                update_video_pts(is, vp-&gt;pts, vp-&gt;pos, vp-&gt;serial);
            SDL_UnlockMutex(is-&gt;pictq.mutex);

            if (frame_queue_nb_remaining(&amp;is-&gt;pictq) &gt; 1) {
                Frame *nextvp = frame_queue_peek_next(&amp;is-&gt;pictq);
                duration = vp_duration(is, vp, nextvp);
                if(!is-&gt;step &amp;&amp; (ffp-&gt;framedrop &gt; 0 || (ffp-&gt;framedrop &amp;&amp; get_master_sync_type(is) != AV_SYNC_VIDEO_MASTER)) &amp;&amp; time &gt; is-&gt;frame_timer + duration) {
                    frame_queue_next(&amp;is-&gt;pictq);
                    goto retry;
                }
            }

            if (is-&gt;subtitle_st) {
                while (frame_queue_nb_remaining(&amp;is-&gt;subpq) &gt; 0) {
                    sp = frame_queue_peek(&amp;is-&gt;subpq);

                    if (frame_queue_nb_remaining(&amp;is-&gt;subpq) &gt; 1)
                        sp2 = frame_queue_peek_next(&amp;is-&gt;subpq);
                    else
                        sp2 = NULL;

                    if (sp-&gt;serial != is-&gt;subtitleq.serial
                            || (is-&gt;vidclk.pts &gt; (sp-&gt;pts + ((float) sp-&gt;sub.end_display_time / 1000)))
                            || (sp2 &amp;&amp; is-&gt;vidclk.pts &gt; (sp2-&gt;pts + ((float) sp2-&gt;sub.start_display_time / 1000))))
                    {
                        if (sp-&gt;uploaded) {
                            ffp_notify_msg4(ffp, FFP_MSG_TIMED_TEXT, 0, 0, &quot;&quot;, 1);
                        }
                        frame_queue_next(&amp;is-&gt;subpq);
                    } else {
                        break;
                    }
                }
            }

            frame_queue_next(&amp;is-&gt;pictq);
            is-&gt;force_refresh = 1;

            SDL_LockMutex(ffp-&gt;is-&gt;play_mutex);
            if (is-&gt;step) {
                is-&gt;step = 0;
                if (!is-&gt;paused)
                    stream_update_pause_l(ffp);
            }
            SDL_UnlockMutex(ffp-&gt;is-&gt;play_mutex);
        }
display:
        /* display picture */
        if (!ffp-&gt;display_disable &amp;&amp; is-&gt;force_refresh &amp;&amp; is-&gt;show_mode == SHOW_MODE_VIDEO &amp;&amp; is-&gt;pictq.rindex_shown)
            //①
            video_display2(ffp);
    }
    is-&gt;force_refresh = 0;
    if (ffp-&gt;show_status) {
        static int64_t last_time;
        int64_t cur_time;
        int aqsize, vqsize, sqsize __unused;
        double av_diff;

        cur_time = av_gettime_relative();
        if (!last_time || (cur_time - last_time) &gt;= 30000) {
            aqsize = 0;
            vqsize = 0;
            sqsize = 0;
            if (is-&gt;audio_st)
                aqsize = is-&gt;audioq.size;
            if (is-&gt;video_st)
                vqsize = is-&gt;videoq.size;
#ifdef FFP_MERGE
            if (is-&gt;subtitle_st)
                sqsize = is-&gt;subtitleq.size;
#else
            sqsize = 0;
#endif
            av_diff = 0;
            if (is-&gt;audio_st &amp;&amp; is-&gt;video_st)
                av_diff = get_clock(&amp;is-&gt;audclk) - get_clock(&amp;is-&gt;vidclk);
            else if (is-&gt;video_st)
                av_diff = get_master_clock(is) - get_clock(&amp;is-&gt;vidclk);
            else if (is-&gt;audio_st)
                av_diff = get_master_clock(is) - get_clock(&amp;is-&gt;audclk);
            av_log(NULL, AV_LOG_INFO,
                   &quot;%7.2f %s:%7.3f fd=%4d aq=%5dKB vq=%5dKB sq=%5dB f=%&quot;PRId64&quot;/%&quot;PRId64&quot;   \r&quot;,
                   get_master_clock(is),
                   (is-&gt;audio_st &amp;&amp; is-&gt;video_st) ? &quot;A-V&quot; : (is-&gt;video_st ? &quot;M-V&quot; : (is-&gt;audio_st ? &quot;M-A&quot; : &quot;   &quot;)),
                   av_diff,
                   is-&gt;frame_drops_early + is-&gt;frame_drops_late,
                   aqsize / 1024,
                   vqsize / 1024,
                   sqsize,
                   is-&gt;video_st ? is-&gt;viddec.avctx-&gt;pts_correction_num_faulty_dts : 0,
                   is-&gt;video_st ? is-&gt;viddec.avctx-&gt;pts_correction_num_faulty_pts : 0);
            fflush(stdout);
            last_time = cur_time;
        }
    }
}</code></pre>
<p>一长串代码，貌似有一些根据时钟来同步音视频的代码？暂时不做分析，这里面要跳转到方法（用①做了标记，有两处）：</p>
<pre><code class="c">//①
video_display2(ffp);</code></pre>
<pre><code class="c">/* display the current picture, if any */
static void video_display2(FFPlayer *ffp)
{
    VideoState *is = ffp-&gt;is;
    if (is-&gt;video_st)
        video_image_display2(ffp);
}</code></pre>
<pre><code class="c">static void video_image_display2(FFPlayer *ffp)
{
    VideoState *is = ffp-&gt;is;
    Frame *vp;
    Frame *sp = NULL;
    //is-&gt;pictq就是picture queue的意思。读取队列中最后一帧。
    vp = frame_queue_peek_last(&amp;is-&gt;pictq);
    //如果帧中的SDL_VoutOverlay数据不为null，那么就开始渲染
    if (vp-&gt;bmp) {
        //如果字幕流不为空，去渲染字幕
        if (is-&gt;subtitle_st) {
            if (frame_queue_nb_remaining(&amp;is-&gt;subpq) &gt; 0) {
                sp = frame_queue_peek(&amp;is-&gt;subpq);

                if (vp-&gt;pts &gt;= sp-&gt;pts + ((float) sp-&gt;sub.start_display_time / 1000)) {
                    if (!sp-&gt;uploaded) {
                        if (sp-&gt;sub.num_rects &gt; 0) {
                            char buffered_text[4096];
                            if (sp-&gt;sub.rects[0]-&gt;text) {
                                strncpy(buffered_text, sp-&gt;sub.rects[0]-&gt;text, 4096);
                            }
                            else if (sp-&gt;sub.rects[0]-&gt;ass) {
                                parse_ass_subtitle(sp-&gt;sub.rects[0]-&gt;ass, buffered_text);
                            }
                            ffp_notify_msg4(ffp, FFP_MSG_TIMED_TEXT, 0, 0, buffered_text, sizeof(buffered_text));
                        }
                        sp-&gt;uploaded = 1;
                    }
                }
            }
        }
        if (ffp-&gt;render_wait_start &amp;&amp; !ffp-&gt;start_on_prepared &amp;&amp; is-&gt;pause_req) {
            if (!ffp-&gt;first_video_frame_rendered) {
                ffp-&gt;first_video_frame_rendered = 1;
                ffp_notify_msg1(ffp, FFP_MSG_VIDEO_RENDERING_START);
            }
            while (is-&gt;pause_req &amp;&amp; !is-&gt;abort_request) {
                SDL_Delay(20);
            }
        }
        //显示YUV数据。
        SDL_VoutDisplayYUVOverlay(ffp-&gt;vout, vp-&gt;bmp);
        ffp-&gt;stat.vfps = SDL_SpeedSamplerAdd(&amp;ffp-&gt;vfps_sampler, FFP_SHOW_VFPS_FFPLAY, &quot;vfps[ffplay]&quot;);
        if (!ffp-&gt;first_video_frame_rendered) {
            ffp-&gt;first_video_frame_rendered = 1;
            ffp_notify_msg1(ffp, FFP_MSG_VIDEO_RENDERING_START);
        }

        if (is-&gt;latest_video_seek_load_serial == vp-&gt;serial) {
            int latest_video_seek_load_serial = __atomic_exchange_n(&amp;(is-&gt;latest_video_seek_load_serial), -1, memory_order_seq_cst);
            if (latest_video_seek_load_serial == vp-&gt;serial) {
                ffp-&gt;stat.latest_seek_load_duration = (av_gettime() - is-&gt;latest_seek_load_start_at) / 1000;
                if (ffp-&gt;av_sync_type == AV_SYNC_VIDEO_MASTER) {
                    ffp_notify_msg2(ffp, FFP_MSG_VIDEO_SEEK_RENDERING_START, 1);
                } else {
                    ffp_notify_msg2(ffp, FFP_MSG_VIDEO_SEEK_RENDERING_START, 0);
                }
            }
        }
    }
}</code></pre>
<p>首先看到取视频帧的这一段代码：</p>
<pre><code class="c">Frame *vp;
Frame *sp = NULL;
//is-&gt;pictq就是picture queue的意思。读取队列中最后一帧。
vp = frame_queue_peek_last(&amp;is-&gt;pictq);</code></pre>
<p>在这里，<code>Frame</code>就是每一帧解码后的图像数据，是直接拿去显示的。而<code>is-&gt;pictq</code>就是<code>VideoState</code>里面的解码后的图像队列<code>FrameQueue</code>。</p>
<p>看一下<code>Frame</code>和<code>FrameQueue</code></p>
<pre><code class="c">typedef struct Frame {
    AVFrame *frame;//ffmpeg定义的数据结构，里面存着buffer，存着真实的yuv图像数据
    AVSubtitle sub;//字幕数据
    int serial;
    double pts;           /* presentation timestamp for the frame */
    double duration;      /* estimated duration of the frame */
    int64_t pos;          /* byte position of the frame in the input file */
#ifdef FFP_MERGE
    SDL_Texture *bmp;
#else
    SDL_VoutOverlay *bmp;//vout设备
#endif
    int allocated;
    int width;
    int height;
    int format;
    AVRational sar;
    int uploaded;
} Frame;

typedef struct FrameQueue {
    Frame queue[FRAME_QUEUE_SIZE];//数组
    int rindex;//read index。下一个读取的下标
    int windex;//write index。下一个写入的下标
    int size;
    int max_size;
    int keep_last;
    int rindex_shown;
    SDL_mutex *mutex;
    SDL_cond *cond;
    PacketQueue *pktq;//引用的未解码的包队列
} FrameQueue;</code></pre>
<p>然后是看到渲染的这一句：</p>
<pre><code class="c">//显示YUV数据。这个vp是Frame，而这个bmp是bitmap的意思
SDL_VoutDisplayYUVOverlay(ffp-&gt;vout, vp-&gt;bmp);</code></pre>
<p>这里的意思是将vp-&gt;bmp中的数据输送到ffp-&gt;vout中。<br>ffp);<br>            is-&gt;last_vis_time = time;<br>        }<br>        <em>remaining_time = FFMIN(</em>remaining_time, is-&gt;last_vis_time + ffp-&gt;rdftspeed - time);<br>    }</p>
<pre><code>if (is-&gt;video_st) {</code></pre><p>retry:<br>        if (frame_queue_nb_remaining(&amp;is-&gt;pictq) == 0) {<br>            // nothing to do, no picture to display in the queue<br>        } else {<br>            double last_duration, duration, delay;<br>            Frame *vp, *lastvp;</p>
<pre><code>        /* dequeue the picture */
        lastvp = frame_queue_peek_last(&amp;is-&gt;pictq);
        vp = frame_queue_peek(&amp;is-&gt;pictq);

        if (vp-&gt;serial != is-&gt;videoq.serial) {
            frame_queue_next(&amp;is-&gt;pictq);
            goto retry;
        }

        if (lastvp-&gt;serial != vp-&gt;serial)
            is-&gt;frame_timer = av_gettime_relative() / 1000000.0;

        if (is-&gt;paused)
            goto display;

        /* compute nominal last_duration */
        last_duration = vp_duration(is, lastvp, vp);
        delay = compute_target_delay(ffp, last_duration, is);

        time= av_gettime_relative()/1000000.0;
        if (isnan(is-&gt;frame_timer) || time &lt; is-&gt;frame_timer)
            is-&gt;frame_timer = time;
        if (time &lt; is-&gt;frame_timer + delay) {
            *remaining_time = FFMIN(is-&gt;frame_timer + delay - time, *remaining_time);
            goto display;
        }

        is-&gt;frame_timer += delay;
        if (delay &gt; 0 &amp;&amp; time - is-&gt;frame_timer &gt; AV_SYNC_THRESHOLD_MAX)
            is-&gt;frame_timer = time;

        SDL_LockMutex(is-&gt;pictq.mutex);
        if (!isnan(vp-&gt;pts))
            update_video_pts(is, vp-&gt;pts, vp-&gt;pos, vp-&gt;serial);
        SDL_UnlockMutex(is-&gt;pictq.mutex);

        if (frame_queue_nb_remaining(&amp;is-&gt;pictq) &gt; 1) {
            Frame *nextvp = frame_queue_peek_next(&amp;is-&gt;pictq);
            duration = vp_duration(is, vp, nextvp);
            if(!is-&gt;step &amp;&amp; (ffp-&gt;framedrop &gt; 0 || (ffp-&gt;framedrop &amp;&amp; get_master_sync_type(is) != AV_SYNC_VIDEO_MASTER)) &amp;&amp; time &gt; is-&gt;frame_timer + duration) {
                frame_queue_next(&amp;is-&gt;pictq);
                goto retry;
            }
        }

        if (is-&gt;subtitle_st) {
            while (frame_queue_nb_remaining(&amp;is-&gt;subpq) &gt; 0) {
                sp = frame_queue_peek(&amp;is-&gt;subpq);

                if (frame_queue_nb_remaining(&amp;is-&gt;subpq) &gt; 1)
                    sp2 = frame_queue_peek_next(&amp;is-&gt;subpq);
                else
                    sp2 = NULL;

                if (sp-&gt;serial != is-&gt;subtitleq.serial
                        || (is-&gt;vidclk.pts &gt; (sp-&gt;pts + ((float) sp-&gt;sub.end_display_time / 1000)))
                        || (sp2 &amp;&amp; is-&gt;vidclk.pts &gt; (sp2-&gt;pts + ((float) sp2-&gt;sub.start_display_time / 1000))))
                {
                    if (sp-&gt;uploaded) {
                        ffp_notify_msg4(ffp, FFP_MSG_TIMED_TEXT, 0, 0, &quot;&quot;, 1);
                    }
                    frame_queue_next(&amp;is-&gt;subpq);
                } else {
                    break;
                }
            }
        }

        frame_queue_next(&amp;is-&gt;pictq);
        is-&gt;force_refresh = 1;

        SDL_LockMutex(ffp-&gt;is-&gt;play_mutex);
        if (is-&gt;step) {
            is-&gt;step = 0;
            if (!is-&gt;paused)
                stream_update_pause_l(ffp);
        }
        SDL_UnlockMutex(ffp-&gt;is-&gt;play_mutex);
    }</code></pre><p>display:<br>        /* display picture */<br>        if (!ffp-&gt;display_disable &amp;&amp; is-&gt;force_refresh &amp;&amp; is-&gt;show_mode == SHOW_MODE_VIDEO &amp;&amp; is-&gt;pictq.rindex_shown)<br>            //①<br>            video_display2(ffp);<br>    }<br>    is-&gt;force_refresh = 0;<br>    if (ffp-&gt;show_status) {<br>        static int64_t last_time;<br>        int64_t cur_time;<br>        int aqsize, vqsize, sqsize __unused;<br>        double av_diff;</p>
<pre><code>    cur_time = av_gettime_relative();
    if (!last_time || (cur_time - last_time) &gt;= 30000) {
        aqsize = 0;
        vqsize = 0;
        sqsize = 0;
        if (is-&gt;audio_st)
            aqsize = is-&gt;audioq.size;
        if (is-&gt;video_st)
            vqsize = is-&gt;videoq.size;</code></pre><p>#ifdef FFP_MERGE<br>            if (is-&gt;subtitle_st)<br>                sqsize = is-&gt;subtitleq.size;<br>#else<br>            sqsize = 0;<br>#endif<br>            av_diff = 0;<br>            if (is-&gt;audio_st &amp;&amp; is-&gt;video_st)<br>                av_diff = get_clock(&amp;is-&gt;audclk) - get_clock(&amp;is-&gt;vidclk);<br>            else if (is-&gt;video_st)<br>                av_diff = get_master_clock(is) - get_clock(&amp;is-&gt;vidclk);<br>            else if (is-&gt;audio_st)<br>                av_diff = get_master_clock(is) - get_clock(&amp;is-&gt;audclk);<br>            av_log(NULL, AV_LOG_INFO,<br>                   “%7.2f %s:%7.3f fd=%4d aq=%5dKB vq=%5dKB sq=%5dB f=%”PRId64”/%”PRId64”   \r”,<br>                   get_master_clock(is),<br>                   (is-&gt;audio_st &amp;&amp; is-&gt;video_st) ? “A-V” : (is-&gt;video_st ? “M-V” : (is-&gt;audio_st ? “M-A” : “   “)),<br>                   av_diff,<br>                   is-&gt;frame_drops_early + is-&gt;frame_drops_late,<br>                   aqsize / 1024,<br>                   vqsize / 1024,<br>                   sqsize,<br>                   is-&gt;video_st ? is-&gt;viddec.avctx-&gt;pts_correction_num_faulty_dts : 0,<br>                   is-&gt;video_st ? is-&gt;viddec.avctx-&gt;pts_correction_num_faulty_pts : 0);<br>            fflush(stdout);<br>            last_time = cur_time;<br>        }<br>    }<br>}</p>
<pre><code>
一长串代码，貌似有一些根据时钟来同步音视频的代码？暂时不做分析，这里面要跳转到方法（用①做了标记，有两处）：

``` c
//①
video_display2(ffp);</code></pre><pre><code class="c">/* display the current picture, if any */
static void video_display2(FFPlayer *ffp)
{
    VideoState *is = ffp-&gt;is;
    if (is-&gt;video_st)
        video_image_display2(ffp);
}</code></pre>
<p>``` c<br>static void video_image_display2(FFPlayer *ffp)<br>{<br>    VideoState *is = ffp-&gt;is;<br>    Frame *vp;<br>    Frame *sp = NULL;<br>    //is-&gt;pictq就是picture queue的意思。读取队列中最后一帧。<br>    vp = frame_queue_peek_last(&amp;is-&gt;pictq);<br>    //如果帧中的SDL_VoutOverlay数据不为null，那么就开始渲染<br>    if (vp-&gt;bmp) {<br>        //如果字幕流不为空，去渲染字幕<br>        if (is-&gt;subtitle_st) {<br>            if (frame_queue_nb_remaining(&amp;is-&gt;subpq) &gt; 0) {<br>                sp = frame_queue_peek(&amp;is-&gt;subpq);</p>
<pre><code>            if (vp-&gt;pts &gt;= sp-&gt;pts + ((float) sp-&gt;sub.start_display_time / 1000)) {
                if (!sp-&gt;uploaded) {
                    if (sp-&gt;sub.num_rects &gt; 0) {
                        char buffered_text[4096];
                        if (sp-&gt;sub.rects[0]-&gt;text) {
                            strncpy(buffered_text, sp-&gt;sub.rects[0]-&gt;text, 4096);
                        }
                        else if (sp-&gt;sub.rects[0]-&gt;ass) {
                            parse_ass_subtitle(sp-&gt;sub.rects[0]-&gt;ass, buffered_text);
                        }
                        ffp_notify_msg4(ffp, FFP_MSG_TIMED_TEXT, 0, 0, buffered_text, sizeof(buffered_text));
                    }
                    sp-&gt;uploaded = 1;
                }
            }
        }
    }
    if (ffp-&gt;render_wait_start &amp;&amp; !ffp-&gt;start_on_prepared &amp;&amp; is-&gt;pause_req) {
        if (!ffp-&gt;first_video_frame_rendered) {
            ffp-&gt;first_video_frame_rendered = 1;
            ffp_notify_msg1(ffp, FFP_MSG_VIDEO_RENDERING_START);
        }
        while (is-&gt;pause_req &amp;&amp; !is-&gt;abort_request) {
            SDL_Delay(20);
        }
    }
    //显示YUV数据。
    SDL_VoutDisplayYUVOverlay(ffp-&gt;vout, vp-&gt;bmp);
    ffp-&gt;stat.vfps = SDL_SpeedSamplerAdd(&amp;ffp-&gt;vfps_sampler, FFP_SHOW_VFPS_FFPLAY, &quot;vfps[ffplay]&quot;);
    if (!ffp-&gt;first_video_frame_rendered) {
        ffp-&gt;first_video_frame_rendered = 1;
        ffp_notify_msg1(ffp, FFP_MSG_VIDEO_RENDERING_START);
    }

    if (is-&gt;latest_video_seek_load_serial == vp-&gt;serial) {
        int latest_video_seek_load_serial = __atomic_exchange_n(&amp;(is-&gt;latest_video_seek_load_serial), -1, memory_order_seq_cst);
        if (latest_video_seek_load_serial == vp-&gt;serial) {
            ffp-&gt;stat.latest_seek_load_duration = (av_gettime() - is-&gt;latest_seek_load_start_at) / 1000;
            if (ffp-&gt;av_sync_type == AV_SYNC_VIDEO_MASTER) {
                ffp_notify_msg2(ffp, FFP_MSG_VIDEO_SEEK_RENDERING</code></pre>
            </div>
            <hr>
            <div>
              <p>
                
                  <span>
                <i class="iconfont icon-inbox"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91/">音视频开发</a>
                      &nbsp;
                    
                  </span>&nbsp;&nbsp;
                
                
              </p>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <div class="post-prev col-6">
                    
                    
                      <a href="/2020/01/09/Java/Throwable%E7%9A%84%E4%BD%BF%E7%94%A8/">
                        <i class="fa fa-chevron-left"></i>
                        <span class="hidden-mobile">Throwable的使用</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </div>
                  <div class="post-next col-6">
                    
                    
                      <a href="/2019/12/30/%E9%9F%B3%E8%A7%86%E9%A2%91%E5%BC%80%E5%8F%91/%E7%90%86%E8%A7%A3ijkplayer%EF%BC%88%E5%9B%9B%EF%BC%89%E6%8B%89%E6%B5%81/">
                        <span class="hidden-mobile">理解ijkplayer（四）拉流</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="fa fa-chevron-right"></i>
                      </a>
                    
                  </div>
                </div>
              
            </div>

              
                <!-- Comments -->
                <div class="comments" id="comments">
                  
                  
  <script defer src="https://utteranc.es/client.js"
          repo="HWilliamgo/HWilliamgo.github.io"
          issue-term="pathname"
  
          label="utterances"
    
          theme="github-light"
          crossorigin="anonymous"
  >
  </script>


                </div>
              
          </div>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc-start"></div>
<div id="toc">
  <p class="h5"><i class="far fa-list-alt"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    </div>
    

    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/popper.js/1.16.1/umd/popper.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="https://cdn.staticfile.org/mdbootstrap/4.13.0/js/mdb.min.js" ></script>
<script  src="/js/main.js" ></script>


  <script  src="/js/lazyload.js" ></script>



  
  <script  src="https://cdn.staticfile.org/tocbot/4.10.0/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var navHeight = $('#navbar').height();
      var toc = $('#toc');
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;
      var tocLimMax = 2 * boardTop + boardCtn.height();

      $(window).scroll(function () {
        var tocLimMin = $('#toc-start').offset().top - navHeight;
        var scroH = document.body.scrollTop + document.documentElement.scrollTop;

        if (tocLimMin <= scroH && scroH <= tocLimMax) {
          toc.css({
            'display': 'block',
            'position': 'fixed',
            'top': navHeight,
          });
        } else if (scroH <= tocLimMin) {
          toc.css({
            'position': '',
            'top': '',
          });
        } else if (scroH > tocLimMax) {
          toc.css('display', 'none');
        }
      });
      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '.post-content',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc > p').css('visibility', 'visible');
      }
      var offset = boardCtn.css('margin-right')
      $('#toc-ctn').css({
        'right': offset
      })
    });
  </script>





  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>





  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




<!-- Plugins -->



  <script  src="https://cdn.staticfile.org/prettify/188.0.0/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "理解ijkplayer（五）解码、播放&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script defer src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>












</body>
</html>
